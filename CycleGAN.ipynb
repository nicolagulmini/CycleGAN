{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CycleGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# CycleGAN for pokemon artworks - hand drawn sketches translation"
      ],
      "metadata": {
        "id": "VHFz9efLPja7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61M32QnkGtPB",
        "outputId": "70fae828-54e1-45bb-f6f5-6b9880bd5e90"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'CycleGAN'...\n",
            "remote: Enumerating objects: 4390, done.\u001b[K\n",
            "remote: Counting objects: 100% (4390/4390), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4387/4387), done.\u001b[K\n",
            "remote: Total 4390 (delta 6), reused 4381 (delta 3), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (4390/4390), 80.95 MiB | 20.45 MiB/s, done.\n",
            "Resolving deltas: 100% (6/6), done.\n",
            "Collecting git+https://www.github.com/keras-team/keras-contrib.git\n",
            "  Cloning https://www.github.com/keras-team/keras-contrib.git to /tmp/pip-req-build-cd847i01\n",
            "  Running command git clone -q https://www.github.com/keras-team/keras-contrib.git /tmp/pip-req-build-cd847i01\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from keras-contrib==2.0.8) (2.7.0)\n",
            "Building wheels for collected packages: keras-contrib\n",
            "  Building wheel for keras-contrib (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-contrib: filename=keras_contrib-2.0.8-py3-none-any.whl size=101077 sha256=72690196f4df1ff3864090d095fbf1718471aec9638dac8ec05d5878a82b1d71\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tbjo661m/wheels/bb/1f/f2/b57495012683b6b20bbae94a3915ec79753111452d79886abc\n",
            "Successfully built keras-contrib\n",
            "Installing collected packages: keras-contrib\n",
            "Successfully installed keras-contrib-2.0.8\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/nicolagulmini/CycleGAN/\n",
        "!pip install git+https://www.github.com/keras-team/keras-contrib.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import cv2 as cv\n",
        "from numpy import asarray, zeros, ones\n",
        "import os\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.models import Model\n",
        "from keras.models import Input\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers import Conv2DTranspose\n",
        "from keras.layers import Activation\n",
        "from keras.layers import Concatenate\n",
        "from keras.layers import BatchNormalization\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization\n",
        "from keras.utils.vis_utils import plot_model\n",
        "from numpy.random import randint, random"
      ],
      "metadata": {
        "id": "X2Pz5M4VGx-z"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Processing"
      ],
      "metadata": {
        "id": "mWGsYp9QPgzX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./CycleGAN/pokemon_artworks_dataset\"\n",
        "files = os.listdir(path)\n",
        "pokemon = []\n",
        "for f in files:\n",
        "    #img = cv.cvtColor(cv.imread(path+\"/\"+f), cv.COLOR_BGR2RGB)\n",
        "    img = cv.imread(path+\"/\"+f, cv.IMREAD_UNCHANGED)\n",
        "    trans_mask = img[:,:,3] == 0\n",
        "    img[trans_mask] = [255, 255, 255, 255]\n",
        "    img = cv.cvtColor(img, cv.COLOR_BGRA2RGB)\n",
        "    img = img / 255.0\n",
        "    resized = cv.resize(img, (128, 128), interpolation = cv.INTER_AREA)\n",
        "    pokemon.append(resized)\n",
        "pokemon = asarray(pokemon)"
      ],
      "metadata": {
        "id": "8nqr9P6pG8QP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"./CycleGAN/animals_sketches_dataset\"\n",
        "files = os.listdir(path)\n",
        "animals = []\n",
        "for f in files:\n",
        "    animals.append(cv.resize(cv.imread(path+\"/\"+f), (128, 128), interpolation = cv.INTER_AREA)/255.0)\n",
        "animals = asarray(animals)"
      ],
      "metadata": {
        "id": "F1BrS6xbElu2"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# information on the two datasets:\n",
        "print('pokemon dataset shape:', pokemon.shape)\n",
        "print('animals sketches dataset shape:', animals.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KhaBT92xIMsk",
        "outputId": "1ef41769-7618-43a0-b6b7-76961381ad18"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pokemon dataset shape: (824, 128, 128, 3)\n",
            "animals sketches dataset shape: (644, 128, 128, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_shape = (128, 128, 3)"
      ],
      "metadata": {
        "id": "XsIJkkfwiKUR"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model definition"
      ],
      "metadata": {
        "id": "iup3XAt3PuGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def define_discriminator(image_shape):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\td = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(in_image)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(256, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(512, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\td = Conv2D(512, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\td = InstanceNormalization(axis=-1)(d)\n",
        "\td = LeakyReLU(alpha=0.2)(d)\n",
        "\tpatch_out = Conv2D(1, (4,4), padding='same', kernel_initializer=init)(d)\n",
        "\tmodel = Model(in_image, patch_out)\n",
        "\tmodel.compile(loss='mse', optimizer=Adam(learning_rate=0.0002, beta_1=0.5), loss_weights=[0.5])\n",
        "\treturn model\n",
        "\n",
        "model = define_discriminator(image_shape)\n",
        "#model.summary()\n",
        "#plot_model(model, to_file='discriminator_model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "2Y30rL9kPUzF"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet_block(n_filters, input_layer):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(input_layer)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\tg = Conv2D(n_filters, (3,3), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\t# concatenate merge channel-wise with input layer\n",
        "\tg = Concatenate()([g, input_layer])\n",
        "\treturn g"
      ],
      "metadata": {
        "id": "Iwlv0wJ7S5nw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_generator(image_shape, n_resnet=9):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tin_image = Input(shape=image_shape)\n",
        "\tg = Conv2D(64, (7,7), padding='same', kernel_initializer=init)(in_image)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\tg = Conv2D(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\tg = Conv2D(256, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\tfor _ in range(n_resnet):\n",
        "\t\tg = resnet_block(256, g)\n",
        "\tg = Conv2DTranspose(128, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\tg = Conv2DTranspose(64, (3,3), strides=(2,2), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tg = Activation('relu')(g)\n",
        "\tg = Conv2D(3, (7,7), padding='same', kernel_initializer=init)(g)\n",
        "\tg = InstanceNormalization(axis=-1)(g)\n",
        "\tout_image = Activation('tanh')(g)\n",
        "\tmodel = Model(in_image, out_image)\n",
        "\treturn model\n",
        "\n",
        "model = define_generator(image_shape)\n",
        "#model.summary()\n",
        "#plot_model(model, to_file='generator_model_plot.png', show_shapes=True, show_layer_names=True)"
      ],
      "metadata": {
        "id": "W5Gx44tGUSD4"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def define_composite_model(g_model_1, d_model, g_model_2, image_shape):\n",
        "\tg_model_1.trainable = True # ensure the model we're updating is trainable\n",
        "\td_model.trainable = False # mark discriminator as not trainable\n",
        "\tg_model_2.trainable = False # mark other generator model as not trainable\n",
        "\n",
        "\t# discriminator element\n",
        "\tinput_gen = Input(shape=image_shape)\n",
        "\tgen1_out = g_model_1(input_gen)\n",
        "\toutput_d = d_model(gen1_out)\n",
        " \n",
        "\t# identity element\n",
        "\tinput_id = Input(shape=image_shape)\n",
        "\toutput_id = g_model_1(input_id)\n",
        " \n",
        "\t# forward cycle\n",
        "\toutput_f = g_model_2(gen1_out)\n",
        "\t# backward cycle\n",
        "\tgen2_out = g_model_2(input_id)\n",
        "\toutput_b = g_model_1(gen2_out)\n",
        "\t# define model graph\n",
        "\tmodel = Model([input_gen, input_id], [output_d, output_id, output_f, output_b])\n",
        "\topt = Adam(learning_rate=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss=['mse', 'mae', 'mae', 'mae'], loss_weights=[1, 5, 10, 10], optimizer=opt)\n",
        "\treturn model\n",
        " \n",
        "g_model_AtoB = define_generator(image_shape)\n",
        "g_model_BtoA = define_generator(image_shape)\n",
        "d_model_A = define_discriminator(image_shape)\n",
        "d_model_B = define_discriminator(image_shape)\n",
        "# composite: A -> B -> [real/fake, A]\n",
        "c_model_AtoB = define_composite_model(g_model_AtoB, d_model_B, g_model_BtoA, image_shape)\n",
        "# composite: B -> A -> [real/fake, B]\n",
        "c_model_BtoA = define_composite_model(g_model_BtoA, d_model_A, g_model_AtoB, image_shape)"
      ],
      "metadata": {
        "id": "sYrrB3p-Udgr"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# select a batch of random samples, returns images and target\n",
        "def generate_real_samples(dataset, n_samples, patch_shape):\n",
        "    X = dataset[randint(0, dataset.shape[0], n_samples)] # random instances of the dataset\n",
        "    # generate 'real' class labels (1)\n",
        "    y = ones((n_samples, patch_shape, patch_shape, 1)) # why ones? why generate real class labels?\n",
        "    return X, y\n",
        "\n",
        "def generate_fake_samples(g_model, dataset, patch_shape):\n",
        "\tX = g_model.predict(dataset) # generate fake instance\n",
        "\ty = zeros((len(X), patch_shape, patch_shape, 1)) # create 'fake' class labels (0)\n",
        "\treturn X, y\n",
        "\n",
        "# update image pool for fake images\n",
        "def update_image_pool(pool, images, max_size=50): # do not understand this\n",
        "    selected = list()\n",
        "    for image in images:\n",
        "        if len(pool) < max_size:\n",
        "            # stock the pool\n",
        "            pool.append(image)\n",
        "            selected.append(image)\n",
        "        elif random() < 0.5:\n",
        "\t\t\t# use image, but don't add it to the pool\n",
        "            selected.append(image)\n",
        "        else:\n",
        "            # replace an existing image and use replaced image\n",
        "            ix = randint(0, len(pool))\n",
        "            selected.append(pool[ix])\n",
        "            pool[ix] = image\n",
        "    return asarray(selected)"
      ],
      "metadata": {
        "id": "JE5DKq_8Vqd_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset):\n",
        "    # define properties of the training run\n",
        "    n_epochs, n_batch, = 50, 16\n",
        "    # determine the output square shape of the discriminator\n",
        "    n_patch = d_model_A.output_shape[1]\n",
        "    # unpack dataset\n",
        "    trainA, trainB = dataset\n",
        "\n",
        "    # prepare image pool for fakes\n",
        "    poolA, poolB = list(), list()\n",
        "    # calculate the number of batches per training epoch\n",
        "    bat_per_epo = int(len(trainA) / n_batch)\n",
        "    # calculate the number of training iterations\n",
        "    n_steps = bat_per_epo * n_epochs\n",
        "\n",
        "    # manually enumerate epochs\n",
        "    for i in range(n_steps):\n",
        "        # select a batch of real samples\n",
        "        X_realA, y_realA = generate_real_samples(trainA, n_batch, n_patch)\n",
        "        X_realB, y_realB = generate_real_samples(trainB, n_batch, n_patch)\n",
        "\n",
        "        # generate a batch of fake samples\n",
        "        X_fakeA, y_fakeA = generate_fake_samples(g_model_BtoA, X_realB, n_patch)\n",
        "        X_fakeB, y_fakeB = generate_fake_samples(g_model_AtoB, X_realA, n_patch)\n",
        "\n",
        "        # update fakes from pool\n",
        "        X_fakeA = update_image_pool(poolA, X_fakeA)\n",
        "        X_fakeB = update_image_pool(poolB, X_fakeB)\n",
        "\n",
        "        # update generator B->A via adversarial and cycle loss\n",
        "        g_loss2, _, _, _, _  = c_model_BtoA.train_on_batch([X_realB, X_realA], [y_realA, X_realA, X_realB, X_realA])\n",
        "\n",
        "        # update discriminator for A -> [real/fake]\n",
        "        dA_loss1 = d_model_A.train_on_batch(X_realA, y_realA)\n",
        "        dA_loss2 = d_model_A.train_on_batch(X_fakeA, y_fakeA)\n",
        "\n",
        "        # update generator A->B via adversarial and cycle loss\n",
        "        g_loss1, _, _, _, _ = c_model_AtoB.train_on_batch([X_realA, X_realB], [y_realB, X_realB, X_realA, X_realB])\n",
        "\n",
        "        # update discriminator for B -> [real/fake]\n",
        "        dB_loss1 = d_model_B.train_on_batch(X_realB, y_realB)\n",
        "        dB_loss2 = d_model_B.train_on_batch(X_fakeB, y_fakeB)\n",
        "\n",
        "        # summarize performance\n",
        "        print('>%d, dA[%.3f,%.3f] dB[%.3f,%.3f] g[%.3f,%.3f]' % (i+1, dA_loss1,dA_loss2, dB_loss1,dB_loss2, g_loss1,g_loss2))"
      ],
      "metadata": {
        "id": "CqfJAYtgVyIw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load a dataset as a list of two numpy arrays\n",
        "dataset = [pokemon, animals]\n",
        "# train models\n",
        "train(d_model_A, d_model_B, g_model_AtoB, g_model_BtoA, c_model_AtoB, c_model_BtoA, dataset)"
      ],
      "metadata": {
        "id": "Wkfd9JfkWLkA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = g_model_BtoA.predict(animals[:3])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "id": "W5RA-oxD1wgD",
        "outputId": "03d4eb2a-6d43-4ccf-882b-1caa6333d8e9"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-d57167d8084d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg_model_BtoA\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manimals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'g_model_BtoA' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.imshow"
      ],
      "metadata": {
        "id": "7eJ1OdedhQ0l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}